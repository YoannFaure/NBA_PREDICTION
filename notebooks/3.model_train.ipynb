{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a pour objectif de pouvoir selectionner les différents hyperparametres utilisés lors de l'entrainement de nos modèles et de les  selectionner. \n",
    "la fonction Utils.megaGridSearch réalise : \n",
    "- le split *(test_size = 0.2)*\n",
    "- test notre gridsearch\n",
    "- Entraine le modèle avec les meilleurs hyperparametres\n",
    "- sauvegarde les informations suivante au format joblib : \n",
    "    - 'name': model_name,\n",
    "    - 'best_params': best_params,\n",
    "    - 'best_model': best_model,\n",
    "    - 'y_pred': y_pred,\n",
    "    - 'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "    - 'classification_report': classification_report(y_test, y_pred),\n",
    "    - 'execution_time_search_params': execution_time_search_params,\n",
    "    - 'execution_time_training': execution_time_training,\n",
    "    - 'accuracy': accuracy_score(y_test, y_pred),\n",
    "    - 'precision': precision_score(y_test, y_pred),\n",
    "    - 'recall': recall_score(y_test, y_pred),\n",
    "    - 'f1_score': f1_score(y_test, y_pred),\n",
    "    - 'auc': roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "Nous pourrons donc utiliser ce process pour entrainer nos modèles sur des dataframes plus spécifiques à l'avenir *(par post de joueur / par zone / ...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "data = pd.read_csv(\"../data/processed/best_player_preprocessed.csv\")\n",
    "features = data.drop('SHOT_MADE_FLAG', axis=1)\n",
    "target = data['SHOT_MADE_FLAG']\n",
    "\n",
    "\n",
    "mgs = Utils.megaGridSearch( name=\"best_player\", features = features, target = target)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = Utils.modelDefinition( name = 'logistic_model',\n",
    "                            params = {\n",
    "                                'penalty': ['l1', 'l2'],\n",
    "                                'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                                'solver': ['liblinear', 'saga'] },\n",
    "                            estimator = LogisticRegression())\n",
    "mgs.AddModel(lr)\n",
    "\n",
    "# Decision tree\n",
    "dt = Utils.modelDefinition( name = 'decision_tree_model',\n",
    "                            params = {\n",
    "                                'splitter': ['best', 'random'],\n",
    "                                'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "                                'min_samples_split': [2, 5, 10],\n",
    "                                'min_samples_leaf': [1, 2, 4] },\n",
    "                            estimator = DecisionTreeClassifier())\n",
    "mgs.AddModel(dt)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = Utils.modelDefinition( name = 'gradient_boosting_model',\n",
    "                            params = {\n",
    "                                'n_estimators': [100, 200],\n",
    "                                'max_depth': [3, 4],\n",
    "                                'subsample': [0.5, 0.6],\n",
    "                                'learning_rate': [0.02, 0.03] },\n",
    "                            estimator = GradientBoostingClassifier())\n",
    "mgs.AddModel(gb)\n",
    "\n",
    "# xgboost_model\n",
    "xgb = Utils.modelDefinition( name = 'xgboost_model',\n",
    "                             params = {\n",
    "                                    'n_estimators': [100, 200],\n",
    "                                    'max_depth': [3, 4],\n",
    "                                    'subsample': [0.5, 0.6],\n",
    "                                    'learning_rate': [0.02, 0.03],\n",
    "                                    'gamma': [0.1, 0.2],\n",
    "                                    'colsample_bytree': [0.5, 0.6] },\n",
    "                             estimator = XGBClassifier())\n",
    "mgs.AddModel(xgb)\n",
    "\n",
    "# Ada Boost\n",
    "abm = Utils.modelDefinition( name = 'adaboost_model',\n",
    "                             params = {\n",
    "                                    'n_estimators': [50, 100, 150],\n",
    "                                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                                    'algorithm': ['SAMME', 'SAMME.R']},\n",
    "                             estimator = AdaBoostClassifier())\n",
    "mgs.AddModel(abm)\n",
    "\n",
    "\n",
    "# LightGBM\n",
    "lgb = Utils.modelDefinition( name = 'lightgbm_model',\n",
    "                             params = {\n",
    "                                    'n_estimators': [100, 200],\n",
    "                                    'max_depth': [3, 4],\n",
    "                                    'learning_rate': [0.02, 0.03],\n",
    "                                    'subsample': [0.5, 0.6],\n",
    "                                    'objective': ['binary'],\n",
    "                                    'metric': ['binary_error']},\n",
    "                             estimator = LGBMClassifier())\n",
    "mgs.AddModel(lgb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgs.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
