{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce noteBook permet de générer un rapport à partir des différents modèles entrainés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "\n",
    "print(sns.__version__)\n",
    "\n",
    "# assign directory\n",
    "directory = '../models/best_player/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "data_split = joblib.load('../models/best_player/best_player_split.joblib')\n",
    "\n",
    "# Extract split\n",
    "X_train = data_split['X_train']\n",
    "X_test = data_split['X_test']\n",
    "y_train = data_split['y_train']\n",
    "y_test = data_split['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_report.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir le fichier en mode écriture\n",
    "with open('../models/best_player/model_report.txt', 'w') as report_file:\n",
    "\n",
    "    # iterate over files in # that directory\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"model.joblib\"):\n",
    "            model_data = joblib.load(f)\n",
    "            report_file.write(f\"Informations pour le modèle: {model_data['name']}\\n\")\n",
    "            report_file.write(\"----\\n\")\n",
    "\n",
    "            # Best params (supposons qu'ils sont stockés dans le modèle)\n",
    "            report_file.write(f\"Best Params: {model_data['best_params']}\\n\")\n",
    "\n",
    "            # Temps d'exécution de l'entraînement\n",
    "            report_file.write(f\"execution time search params: {model_data['execution_time_search_params']} seconds\\n\")\n",
    "\n",
    "            # Temps d'exécution de l'entraînement\n",
    "            report_file.write(f\"Execution Time Training: {model_data['execution_time_training']} seconds\\n\")\n",
    "\n",
    "            # Matrice de confusion\n",
    "            report_file.write(\"Confusion Matrix:\\n\")\n",
    "            report_file.write(f\"{model_data['confusion_matrix']}\\n\")\n",
    "\n",
    "            # Rapport de classification\n",
    "            report_file.write(\"Classification Report:\\n\")\n",
    "            report_file.write(f\"{model_data['classification_report']}\\n\")\n",
    "\n",
    "            report_file.write(\"----\\n\")\n",
    "\n",
    "# Afficher un message indiquant que le rapport a été enregistré\n",
    "print(f\"Le rapport des modèles a été enregistré dans '{report_file.name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une liste pour stocker les informations sur chaque modèle\n",
    "models_info = []\n",
    "\n",
    "# iterate over files in # that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"model.joblib\"):\n",
    "        model_data = joblib.load(f)\n",
    "        info = {\n",
    "            'model_name': model_data['name'],\n",
    "            'execution_time_search_params': model_data['execution_time_search_params'],\n",
    "            'execution_time_training': model_data['execution_time_training'],\n",
    "            'accuracy': model_data['accuracy'],\n",
    "            'precision': model_data['precision'],\n",
    "            'recall': model_data['recall'],\n",
    "            'f1_score': model_data['f1_score'],\n",
    "            'auc': model_data['auc']\n",
    "        }\n",
    "        models_info.append(info)\n",
    "\n",
    "# Créer un DataFrame à partir de la liste de dictionnaires\n",
    "model_report = pd.DataFrame(models_info)\n",
    "display(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy :** Proportion des prédictions correctes par rapport à l'ensemble des prédictions.\n",
    "\n",
    "- **Precision :** Proportion des vrais positifs parmi les prédictions positives du modèle.\n",
    "\n",
    "- **Recall :** Proportion des vrais positifs parmi toutes les valeurs réelles positives.\n",
    "\n",
    "- **F1 Score :** Moyenne harmonique de la précision et du rappel.\n",
    "\n",
    "- **AUC (Area Under the Curve) :** Mesure de la capacité du modèle à discriminer entre les classes, en utilisant la courbe ROC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les informations spécifiques pour chaque modèle dans la sortie de la cellule\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"model.joblib\"):\n",
    "        model_data = joblib.load(f)\n",
    "\n",
    "        # Afficher le nom du modèle\n",
    "        print(f\"Nom du modèle: {model_data['name']}\")\n",
    "\n",
    "        # Afficher les meilleures paramètres\n",
    "        print(f\"Meilleurs paramètres: {model_data['best_params']}\")\n",
    "\n",
    "        # Afficher le temps d'exécution d'entraînement\n",
    "        print(f\"Temps de recherche des hyperparametres : {model_data['execution_time_search_params']} seconds\")\n",
    "\n",
    "        # Afficher le temps d'exécution d'entraînement\n",
    "        print(f\"Temps d'exécution de l'entraînement: {model_data['execution_time_training']} seconds\")\n",
    "\n",
    "        # Afficher la matrice de confusion\n",
    "        print(\"Matrice de confusion:\")\n",
    "        print(model_data['confusion_matrix'])\n",
    "\n",
    "        # Afficher le rapport de classification\n",
    "        print(\"Rapport de classification:\")\n",
    "        print(model_data['classification_report'])\n",
    "\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure avec une grille de sous-graphiques (2 lignes, 3 colonnes)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 6))\n",
    "\n",
    "# Ajuster l'espacement entre les sous-graphiques\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"model.joblib\"):\n",
    "        model_data = joblib.load(f)\n",
    "        # Obtenir la matrice de confusion\n",
    "        cm = model_data['confusion_matrix']\n",
    "\n",
    "        # Calculer les coordonnées dans la grille (2 lignes, 3 colonnes)\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "\n",
    "        # Créer un sous-graphique\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        # Utiliser seaborn pour afficher la matrice de confusion sous forme de heatmap\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', cbar=False, ax=ax)\n",
    "\n",
    "        # Configurer le titre et les étiquettes\n",
    "        ax.set_title(model_data['name'])\n",
    "        ax.set_xlabel('Prédiction')\n",
    "        ax.set_ylabel('Vraie classe')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        # Afficher le graphique\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBA_Inter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
